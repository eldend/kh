{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DxZm83Bg44qO0CBk3-4NESiZZo5ztv_U",
      "authorship_tag": "ABX9TyPxnAyV/sga4SxSBQPxK7sS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eldend/kh/blob/main/%EA%B3%BC%EC%A0%9C1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#--과제1--\n",
        "타이타닉 데이터 세트를 이용하여\n",
        "\n",
        "*   SGD 분류\n",
        "*   결정트리\n",
        "*   랜덤포레스트\n",
        "*   히스토그램기반 그래디언트 부스팅 모델을 만들고 최적화"
      ],
      "metadata": {
        "id": "a2dgXRAfIX9i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cqT4AtlCIU8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d78bd7-a964-4c25-862d-a4e2c381efe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[     Survived  Pclass     Sex        Age\n",
            "0           0       3    male  22.000000\n",
            "1           1       1  female  38.000000\n",
            "2           1       3  female  26.000000\n",
            "3           1       1  female  35.000000\n",
            "4           0       3    male  35.000000\n",
            "..        ...     ...     ...        ...\n",
            "886         0       2    male  27.000000\n",
            "887         1       1  female  19.000000\n",
            "888         0       3  female  29.699118\n",
            "889         1       1    male  26.000000\n",
            "890         0       3    male  32.000000\n",
            "\n",
            "[891 rows x 4 columns],      PassengerId  Pclass     Sex       Age\n",
            "0            892       3    male  34.50000\n",
            "1            893       3  female  47.00000\n",
            "2            894       2    male  62.00000\n",
            "3            895       3    male  27.00000\n",
            "4            896       3  female  22.00000\n",
            "..           ...     ...     ...       ...\n",
            "413         1305       3    male  30.27259\n",
            "414         1306       1  female  39.00000\n",
            "415         1307       3    male  38.50000\n",
            "416         1308       3    male  30.27259\n",
            "417         1309       3    male  30.27259\n",
            "\n",
            "[418 rows x 4 columns]]\n",
            "SGD Accuracy:  0.675645342312009\n",
            "결정트리 Accuracy:  0.8069584736251403\n",
            "랜덤포레스트 Accuracy:  0.8069584736251403\n",
            "히스토기반 그레디언트 부스팅 Accuracy:  0.8058361391694725\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pandas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier # 결정트리\n",
        "from sklearn.preprocessing import StandardScaler #정규화\n",
        "from sklearn.linear_model import SGDClassifier #SGD 분류\n",
        "from sklearn.ensemble import RandomForestClassifier # 랜덤포레스트\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier # 그래디언트 부스팅\n",
        "#from sklearn.model_selection import train_test_split -> 데이터가 이미 나눠져 있기 때문에 나눌 필요가 없음\n",
        "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv')\n",
        "#Age와 Cabin, Embarked에 Nan값이 존재-> Age만 사용할 것이기 때문에 Age만 Nan값을 채움\n",
        "#Age의 경우 편균값으로 변경\n",
        "train['Age'].fillna(train['Age'].mean(), inplace=True)\n",
        "train.isnull().sum().sum()\n",
        "test['Age'].fillna(test['Age'].mean(), inplace=True)\n",
        "test.isnull().sum().sum()\n",
        "#불필요한 필드 삭제(생존에 영향을 미치지 않음)\n",
        "train = train.drop(['Ticket', 'Cabin', 'Name', 'Parch', 'SibSp', 'Embarked', 'Fare', 'PassengerId'], axis=1)\n",
        "test = test.drop(['Ticket', 'Cabin', 'Name', 'Parch', 'SibSp', 'Embarked', 'Fare'], axis=1)\n",
        "#데이터 결합\n",
        "combine = [train, test]\n",
        "print(combine)\n",
        "#성별의 경우 데이터가 string형태이기때문에 여자면 1, 남잠녀 0으로 데이터형식을 변환\n",
        "for dataset in combine:\n",
        "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
        "#나이의 경우 범위가 넓기 때문에 10대 20대와 같이 분류\n",
        "for dataset in combine:\n",
        "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
        "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
        "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
        "#데이터 나누기 -> (정보, 생존여부)와 같은 형태를 만듦\n",
        "X_train = train.drop([\"Survived\"], axis=1)\n",
        "Y_train = train[\"Survived\"]\n",
        "X_test  = test.copy().drop(\"PassengerId\", axis=1)\n",
        "#SGD모델 실행\n",
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train, Y_train) #-> (정보, 생존 여부)\n",
        "Y_pred = sgd.predict(X_test)\n",
        "acc_sgd = sgd.score(X_train, Y_train)\n",
        "print('SGD Accuracy: ', acc_sgd)\n",
        "#결정트리 모델 실행\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "Y_pred = decision_tree.predict(X_test)\n",
        "acc_decision_tree = decision_tree.score(X_train, Y_train)\n",
        "print('결정트리 Accuracy: ', acc_decision_tree)\n",
        "#랜덤포레스트 모델 실행\n",
        "random_forest = RandomForestClassifier(n_jobs= -1, n_estimators=100)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "Y_pred = random_forest.predict(X_test)\n",
        "random_forest.score(X_train, Y_train)\n",
        "acc_random_forest = random_forest.score(X_train, Y_train)\n",
        "print('랜덤포레스트 Accuracy: ', acc_random_forest)\n",
        "#히스토리 기반 그레디언트 부스팅 모델 실행\n",
        "hgb = HistGradientBoostingClassifier(random_state=202139820)\n",
        "hgb.fit(X_train, Y_train)\n",
        "Y_pred = hgb.predict(X_test)\n",
        "acc_hgb = hgb.score(X_train, Y_train)\n",
        "print('히스토기반 그레디언트 부스팅 Accuracy: ', acc_hgb)"
      ]
    }
  ]
}